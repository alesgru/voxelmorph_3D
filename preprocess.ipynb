{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------STEP one : Automatically crop the volumes -----------------------------------------------\n",
    "#-------------with help of segmentation and information of the lesion------------------------- \n",
    "#cropp is disabled currently\n",
    "def preprocess(seg_name, data_name, array_verte, store_name, folder = 'networks', end_size = 200, plot = False, treshold = -1):\n",
    "    \n",
    "    ##############loading#################\n",
    "    DS = False\n",
    "    seg = load_data(seg_name)\n",
    "    data, img = load_data2(data_name)\n",
    "    print('shape data :'+ str(data.shape))\n",
    "    print('shape seg :'+ str(seg.shape))\n",
    "    \n",
    "    ############cropping#########################\n",
    "    cropped_seg, cropped_data = crop_points(seg, array_verte, data) # change\n",
    "    shape = cropped_data.shape\n",
    "    shape_seg = cropped_seg.shape\n",
    "    print('shape of the data after cropping '+ str(shape) )\n",
    "    print('shape of the seg after cropping '+ str(shape_seg) )\n",
    "    \n",
    "    ###############plotting######################\n",
    "    if (plot==True):\n",
    "        #plot_middle_slices(cropped_data,treshold = -1 )\n",
    "        plot_middle_slices(data,treshold = -1)\n",
    "   \n",
    "    \n",
    "    ######downsampling###########\n",
    "    if (DS == True) : \n",
    "        while (max(shape)>end_size):\n",
    "            value = max(shape)\n",
    "            coefficient = end_size/value\n",
    "            if (coefficient< 0.93):\n",
    "                print('yes we are sampling down with coefficent: '+ str(coefficient))\n",
    "                cropped_data = downsample(cropped_data)\n",
    "                cropped_seg = downsample(cropped_seg)\n",
    "            else:\n",
    "                arg_max = np.argmax(shape)\n",
    "                diff = int((value-end_size)/2)\n",
    "                if (arg_max == 0):\n",
    "                    cropped_data = cropped_data[diff:(end_size-diff),:,:]\n",
    "                    cropped_seg = cropped_seg[diff:(end_size-diff),:,:]\n",
    "                elif (arg_max == 1): \n",
    "                    cropped_data = cropped_data[:,diff:(end_size-diff),:]\n",
    "                    cropped_seg = cropped_seg[:,diff:(end_size-diff),:]\n",
    "                elif (arg_max == 2):\n",
    "                    cropped_data = cropped_data[:,:,diff:(end_size-diff)]\n",
    "                    cropped_seg = cropped_data[:,:,diff:(end_size-diff)]\n",
    "\n",
    "\n",
    "            shape = cropped_data.shape\n",
    "\n",
    "        \n",
    "    \n",
    "    ######padding####################\n",
    "    #pad_new_img = center_pad(cropped_data,np.array([end_size,end_size,end_size]))\n",
    "    #pad_seg_img = center_pad(cropped_seg,np.array([end_size,end_size,end_size]))\n",
    "    #shape = pad_new_img.shape\n",
    "    #if (plot==True):\n",
    "    #    plot_middle_slices(pad_seg_img)\n",
    "    #    plot_middle_slices(pad_new_img)\n",
    "    #print('shape of the data after padding '+ str(shape) )\n",
    "    pad_new_img = cropped_data \n",
    "    pad_seg_img = cropped_seg\n",
    "    #############storing################\n",
    "    \n",
    "    pad_nifty_img = nib.Nifti1Image(pad_new_img, affine=img.affine)\n",
    "    #print(type(pad_nifty_img))\n",
    "    #print(pad_nifty_img.shape)\n",
    "    nib.save(pad_nifty_img,os.path.join(folder,store_name + '.nii.gz'))\n",
    "    ####HERE WE COULD SAVE THE SAME JUST TO SEE##\n",
    "    pad_nifty_seg = nib.Nifti1Image(pad_seg_img, affine=np.eye(4))\n",
    "    #print(type(pad_nifty_img))\n",
    "    #print(pad_nifty_img.shape)\n",
    "    nib.save(pad_nifty_seg,os.path.join(folder,store_name + 'seg.nii.gz'))\n",
    "    print('data has been stored in folder :' + str(folder))\n",
    "\n",
    "def crop_points(arr, numbers, data = -1):\n",
    "    concat_x=[]\n",
    "    concat_y=[]\n",
    "    concat_z=[]\n",
    "    shape = arr.shape\n",
    "    \n",
    "    string = \"Vertebras selected are:\"\n",
    "    for i in range(0,len(numbers)):\n",
    "        #'result' % x = np.where(arr==numbers[i])\n",
    "        string = string + str(numbers[i])+ \" \"\n",
    "        globals()['result{}'.format(i)] = np.where(arr==numbers[i])\n",
    "    print(string)\n",
    "        \n",
    "    for i in range(0,len(numbers)):\n",
    "        #print('here')\n",
    "        concat_x= np.concatenate((concat_x,globals()['result{}'.format(i)][0]),axis=0)\n",
    "        concat_y= np.concatenate((concat_y,globals()['result{}'.format(i)][1]),axis=0)\n",
    "        concat_z= np.concatenate((concat_z,globals()['result{}'.format(i)][2]),axis=0)\n",
    "    #print('res0')\n",
    "    #print(result0)\n",
    "    max_x = int(max(concat_x))\n",
    "    max_y = int(max(concat_y))\n",
    "    max_z = int(max(concat_z))\n",
    "    min_x = int(min(concat_x))\n",
    "    min_y = int(min(concat_y))\n",
    "    min_z = int(min(concat_z))\n",
    "    #print(result0)\n",
    "    #print(result1)\n",
    "    print(\"x-Values from  \" + str(min_x)+ \" till \" + str(max_x) )\n",
    "    print(\"y-Values from  \" + str(min_y)+ \" /0 till \" + str(max_y) )\n",
    "    print(\"z-Values from  \" + str(min_z)+ \" till \" + str(max_z) )\n",
    "    \n",
    "    ###mistake with y_min value...seems not to be right but whyy??????\n",
    "    cropped_image = arr[min_x:max_x+1,min_y:max_y,min_z:max_z+1]\n",
    "    if isinstance(data, int) :\n",
    "        data = -1\n",
    "        \n",
    "    else: \n",
    "        data = data[min_x:max_x+1,min_y:max_y,min_z:max_z+1]\n",
    "    return cropped_image, data          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------STEP two: Downsample/crop with treshold --------------------------------------------\n",
    "def downsample_by_factor(img,factor):\n",
    "    down_x = img[range(0,img.shape[0],factor),:,:]\n",
    "    down_y = down_x[:,range(0,img.shape[1],factor),:]\n",
    "    down_z = down_y[:,:,range(0,img.shape[2],factor)]\n",
    "    return down_z\n",
    "\n",
    "\n",
    "#downsample in a whole folder\n",
    "def downsampling_in_whole_folder(end_size, folder_data, folder_store):\n",
    "    baseDir = folder_data\n",
    "    files = glob(baseDir + '/*.nii')\n",
    "    \n",
    "    \n",
    "    for file in files:\n",
    "        cropped_data, img = load_data(file)\n",
    "        shape = cropped_data.shape\n",
    "        print(file)\n",
    "        print(shape)\n",
    "        if (max(shape)> end_size):\n",
    "            ratio = max(shape)/end_size\n",
    "            ratio_int = int(ratio)\n",
    "            rest = ratio - ratio_int\n",
    "            if (rest > 0.30):\n",
    "                ratio_int += 1\n",
    "                cropped_data = downsample_by_factor(cropped_data, ratio_int)\n",
    "                \n",
    "            else:\n",
    "                cropped_data = downsample_by_factor(cropped_data, ratio_int)\n",
    "                shape = cropped_data.shape\n",
    "                while (max(shape)> end_size):\n",
    "                    value = max(shape)\n",
    "                    #coefficient = end_size/value\n",
    "                    arg_max = np.argmax(shape)\n",
    "                    #print('value')\n",
    "                    #print(value)\n",
    "                    #print(end_size)\n",
    "                    #print((value-end_size)/2)\n",
    "                    diff = int((value-end_size)/2)\n",
    "                    if (arg_max == 0):\n",
    "                        cropped_data = cropped_data[diff:(end_size-diff),:,:]\n",
    "                    elif (arg_max == 1):\n",
    "                        #print('in one')\n",
    "                        #print(cropped_data.shape)\n",
    "                        cropped_data = cropped_data[:,diff:(end_size-diff),:]\n",
    "                        #print(diff)\n",
    "                        #print(cropped_data.shape)\n",
    "                    elif (arg_max == 2):\n",
    "                        cropped_data = cropped_data[:,:,diff:(end_size-diff)]\n",
    "                    shape = cropped_data.shape\n",
    "            \n",
    "        #save nifti\n",
    "        print('shape: ', cropped_data.shape)\n",
    "        saveDir = folder_store\n",
    "        #img = nib.Nifti1Image(cropped_data, np.eye(4))\n",
    "        img = nib.Nifti1Image(cropped_data, img.affine)\n",
    "        nib.save(img,os.path.join(saveDir, file[len(baseDir)+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------STEP three: REGISTRATION via IMFUSION -----------------------------------------------------------\n",
    "# rigid registation, same spacing , reset all translation, download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------STEP four: apply the translations calculated in IMFUSION to the images -----------------\n",
    "#(CAREFUL...if a translation is shown in the imfuison load that does not exist in the headerfile... then it can not\n",
    "#be done automatically... extract values from hand and then apply give it to the funtion (- + is exchanged Imfusion vs nib))\n",
    "def translation(data_path,translation = np.array([0,0,0]),saveDir ='.'):\n",
    "    corrected_data, b = load_data(data_path)\n",
    "    #corrected_data = np.array(nifty_data.dataobj)\n",
    "    #translation = img.affine[:,3]\n",
    "    #print('translations:',translation)\n",
    "    corrected_data = np.roll(corrected_data, translation[0], axis = 0)\n",
    "    corrected_data = np.roll(corrected_data, translation[1], axis = 1)\n",
    "    corrected_data = np.roll(corrected_data, translation[2], axis = 2)\n",
    "    corrected_nifty = nib.Nifti1Image(corrected_data, b.affine)\n",
    "    nib.save(corrected_nifty, saveDir + data_path[22:] )\n",
    "    return corrected_data, corrected_nifty\n",
    "translation('.\\\\healthy_reg_applied\\\\healthy1_L1-L3.nii', np.array([0,0,0]), '.\\\\healthy_trans\\\\healthy1_L1-L3.nii')\n",
    "translation('.\\\\healthy_reg_applied\\\\healthy2_L1-L3.nii', np.array([1,0,-1]), '.\\\\healthy_trans\\\\healthy2_L1-L3.nii')\n",
    "translation('.\\\\healthy_reg_applied\\\\healthy3_L1-L3.nii', np.array([2,2,0]), '.\\\\healthy_trans\\\\healthy3_L1-L3.nii')\n",
    "translation('.\\\\healthy_reg_applied\\\\healthy4_L1-L3.nii', np.array([2,1,0]), '.\\\\healthy_trans\\\\healthy4_L1-L3.nii')\n",
    "translation('.\\\\healthy_reg_applied\\\\healthy5_L1-L3.nii', np.array([1,2,0]), '.\\\\healthy_trans\\\\healthy5_L1-L3.nii')\n",
    "translation('.\\\\healthy_reg_applied\\\\healthy6_L1-L3.nii', np.array([0,2,0]), '.\\\\healthy_trans\\\\healthy6_L1-L3.nii')\n",
    "translation('.\\\\healthy_reg_applied\\\\healthy7_L1-L3.nii', np.array([1,3,-1]), '.\\\\healthy_trans\\\\healthy7_L1-L3.nii')\n",
    "translation('.\\\\healthy_reg_applied\\\\healthy8_L1-L3.nii', np.array([0,0,0]), '.\\\\healthy_trans\\\\healthy8_L1-L3.nii')\n",
    "translation('.\\\\healthy_reg_applied\\\\healthy9_L1-L3.nii', np.array([0,0,1]), '.\\\\healthy_trans\\\\healthy9_L1-L3.nii')\n",
    "translation('.\\\\healthy_reg_applied\\\\healthy10_L1-L3.nii', np.array([-1,-3,2]), '.\\\\healthy_trans\\\\healthy10_L1-L3.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------STEP five: Apply img.affine to the images -------------------------------------------------------\n",
    "#(it applies the rotation caclulated in IMFUISON to the images)\n",
    "\n",
    "def round_half_up(n, decimals=0):\n",
    "    multiplier = 10 ** decimals\n",
    "    return math.floor(n*multiplier + 0.5) / multiplier\n",
    "#flag scipy\n",
    "def space_correction(load_dir,store_dir,plot = False, translation = False):\n",
    "    nifty_vol = nib.load(load_dir)\n",
    "    nifty_vol = nib.as_closest_canonical(nifty_vol)\n",
    "    vol_data = np.array(nifty_vol.dataobj)\n",
    "    #matrix = np.linalg.inv(img.affine)\n",
    "    #img.affine[:,3] = [0,0,0,1]\n",
    "    #print(img.affine)\n",
    "    out_vox_map = nib.spaces.vox2out_vox((nifty_vol.shape, nifty_vol.affine))\n",
    "    corrected_nifty = nib.processing.resample_from_to(nifty_vol,out_vox_map)\n",
    "    \n",
    "    if(translation == True):\n",
    "        corrected_data = np.array(corrected_nifty.dataobj)\n",
    "        translation = nifty_vol.affine[:,3]\n",
    "        print('translations:',translation)\n",
    "        corrected_data = np.roll(corrected_data, int(round_half_up(translation[0])) , axis = 0)\n",
    "        corrected_data = np.roll(corrected_data, int(round_half_up(translation[1])), axis = 1)\n",
    "        corrected_data = np.roll(corrected_data, int(round_half_up(translation[2])) , axis = 2)\n",
    "        corrected_nifty = nib.Nifti1Image(corrected_data, np.eye(4))\n",
    "    if (plot == True):\n",
    "        corrected_data = np.array(corrected_nifty.dataobj)\n",
    "        plot_middle_slices(corrected_data)\n",
    "    nib.save(corrected_nifty,store_dir)\n",
    "\n",
    "def apply_affine_from_original_to_child(original, child, saveDir):\n",
    "    child_nifty = nib.load(child)\n",
    "    original_nifty = nib.load(original)\n",
    "    original_nifty = nib.as_closest_canonical(original_nifty)\n",
    "    child_nifty = nib.as_closest_canonical(child_nifty)\n",
    "    child_data = np.array(child_nifty.dataobj)\n",
    "    corrected = nib.Nifti1Image(child_data, original_nifty.affine)\n",
    "    nib.save(corrected,saveDir)\n",
    "def space_correction_folder(baseDir,saveDir):\n",
    "    files = glob(baseDir + '/*.nii')\n",
    "    \n",
    "    for file in files:\n",
    "        space_correction(file,str(saveDir + file[len(baseDir) :]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------STEP six: check the size of our image files again step 5 can change the pixel size----------\n",
    "# if this is true for some volumes you need to crop or downsample them again.. which will have negative impact on your\n",
    "# rigid registration....\n",
    "files = glob('.\\\\cropped\\\\downsampled\\\\64_rotation\\\\'+ '/*.nii')\n",
    "    \n",
    "for file in files:\n",
    "    a,b = load_data(file)\n",
    "    print(a.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
