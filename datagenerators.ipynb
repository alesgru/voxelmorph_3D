{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from myTransforms.ipynb\n"
     ]
    }
   ],
   "source": [
    "from IPhyton_import import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "\n",
    "#### how to store the information which atlas to use(;\n",
    "\"\"\"\n",
    "Datagenerator for Voxelmorph\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from myTransforms import Pad, AdjustBrightness, LimitRange, MyNormalize\n",
    "import myTransforms as mt\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "from scipy.ndimage.filters import median_filter\n",
    "\n",
    "\n",
    "\n",
    "def load_example_by_name(current_vol, atlas_dir, pad_size): \n",
    "   \n",
    "    \"\"\"\n",
    "    load a specific volume (used in test case)\n",
    "    :param current_vol: string name of vol\n",
    "    :param atlas_dir: location of atlas\n",
    "    :param pad_size: size for padding the 3D volumes square\n",
    "    \n",
    "    \"\"\"\n",
    "    #-----------------load the correct atlas for the volume----------------------------------\n",
    "    if current_vol[-9:-4] == 'L1-L3': \n",
    "        ## sometimes files are called nii.gz sometimes nii\n",
    "        try:\n",
    "            A = load_volfile(os.path.join(atlas_dir,'atlas_L1-L3.nii.gz'))\n",
    "        except FileNotFoundError:\n",
    "            A = load_volfile(os.path.join(atlas_dir,'atlas_L1-L3.nii'))\n",
    "        \n",
    "    elif current_vol[-9:-4] == 'L2-L4' :\n",
    "        try:\n",
    "            A = load_volfile(os.path.join(atlas_dir,'atlas_L2-L4.nii.gz'))\n",
    "        except FileNotFoundError:\n",
    "            A = load_volfile(os.path.join(atlas_dir,'atlas_L2-L4.nii'))\n",
    "    elif(current_vol[-9:-4] == 'L3-L5'):\n",
    "        try:\n",
    "            A = load_volfile(os.path.join(atlas_dir,'atlas_L3-L5.nii.gz'))\n",
    "        except FileNotFoundError:\n",
    "            A = load_volfile(os.path.join(atlas_dir,'atlas_L3-L5.nii'))\n",
    "    else: \n",
    "        print('wrong name:',current_vol[-9:-4] )\n",
    "    \n",
    "    \n",
    "    #--------------apply median filter, nomalize and limit the range of the atlas to [-1,1]-------\n",
    "    A = median_filter(A, size=(3,3,3))\n",
    "    composed_atlas = Compose([LimitRange(), MyNormalize()])\n",
    "    #composed_atlas = LimitRange()\n",
    "    A = composed_atlas(A)\n",
    "    A_mean = np.mean(A)\n",
    "    A_std = np.std(A)\n",
    "    \n",
    "    #---------apply median filter, nomalize and limit the range of the current volume to [-1,1]----\n",
    "    X = load_volfile(current_vol)\n",
    "    X = median_filter(X, size=(3,3,3))\n",
    "    composed = LimitRange()\n",
    "    X = composed(X)\n",
    "    X = mt.adjust_brightness(X,A_mean,A_std)\n",
    "    \n",
    "    #--------------pad the volumes and add axes----------------------------------------\n",
    "    pad = Pad(pad_size)\n",
    "    X = pad(X)\n",
    "    A = pad(A)\n",
    "    X = X[np.newaxis, ..., np.newaxis] \n",
    "    A = A[np.newaxis, ..., np.newaxis]\n",
    "    \n",
    "    \n",
    "    return_vals = [X, A]\n",
    "\n",
    "    #if(seg_name):\n",
    "    #    X_seg = np.load(seg_name)['vol_data']\n",
    "    #    X_seg = np.reshape(X_seg, (1,) + X_seg.shape + (1,))\n",
    "    #    return_vals.append(X_seg)\n",
    "\n",
    "    return tuple(return_vals)\n",
    "\n",
    "\n",
    "def load_volfile(datafile):\n",
    "    \"\"\"\n",
    "    load volume file\n",
    "    formats: nii, nii.gz, mgz, npz\n",
    "    if it's a npz (compressed numpy), assume variable names 'vol_data'\n",
    "    \"\"\"\n",
    "    assert datafile.endswith(('.nii', '.nii.gz', '.mgz', '.npz')), 'Unknown data file: %s' % datafile\n",
    "\n",
    "    if datafile.endswith(('.nii', '.nii.gz', '.mgz')):\n",
    "        # import nibabel\n",
    "        if 'nib' not in sys.modules:\n",
    "            try:\n",
    "                import nibabel as nib\n",
    "            except:\n",
    "                print('Failed to import nibabel. need nibabel library for these data file types.')\n",
    "\n",
    "        X = nib.load(datafile)\n",
    "        X = nib.as_closest_canonical(X)\n",
    "        X = X.get_data()\n",
    "\n",
    "    else:  # npz\n",
    "        X = np.load(datafile)['vol_data']\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def example_gen(vol_names, atlas_dir , pad_size, batch_size=1, return_segs=False, seg_dir=None):\n",
    "    # here I give all my file names ... \n",
    "    \"\"\"\n",
    "    generate examples\n",
    "    Parameters:\n",
    "        vol_names: a list or tuple of filenames\n",
    "        atlas_dir: location to folder with the atlases\n",
    "        pad_size: int that refers to the wanted size of the volumes\n",
    "        batch_size: the size of the batch (default: 1)\n",
    "        \n",
    "        These paramaters are from the original implementation, not implemented here :\n",
    "        The following are fairly specific to our data structure, please change to your own\n",
    "        return_segs: logical on whether to return segmentations\n",
    "        seg_dir: the segmentations directory.\n",
    "    \"\"\"\n",
    "    #--------------load all the atlases, apply median filter, normalize and limit range to [-1,1]-----\n",
    "    try:\n",
    "        A1 = load_volfile(os.path.join(atlas_dir,'atlas_L1-L3.nii.gz'))\n",
    "        A1 = median_filter(A1, size=(3,3,3))\n",
    "        A2 = load_volfile(os.path.join(atlas_dir,'atlas_L2-L4.nii.gz'))\n",
    "        A2 = median_filter(A2, size=(3,3,3))\n",
    "        A3 = load_volfile(os.path.join(atlas_dir,'atlas_L3-L5.nii.gz'))\n",
    "        A3 = median_filter(A3, size=(3,3,3))\n",
    "        composed_atlas = Compose([LimitRange(), MyNormalize()])\n",
    "        # pretty put in one array\n",
    "        #composed_atlas = LimitRange()\n",
    "        A1 = composed_atlas(A1)\n",
    "\n",
    "        A2 = composed_atlas(A2)\n",
    "        A3 = composed_atlas(A3)\n",
    "        A1_mean = np.mean(A1)\n",
    "        A1_std = np.std(A1)\n",
    "        A2_mean = np.mean(A2)\n",
    "        A2_std = np.std(A2)\n",
    "        A3_mean = np.mean(A3)\n",
    "        A3_std = np.std(A3)\n",
    "    #------------if nii.gz files are not found then we are using the healthy data which only has one atlas:L1-L3----\n",
    "    except FileNotFoundError:\n",
    "        A1 = load_volfile(os.path.join(atlas_dir,'atlas_L1-L3.nii'))\n",
    "        A1 = median_filter(A1, size=(3,3,3))\n",
    "        #A2 = load_volfile(os.path.join(atlas_dir,'atlas_L2-L4.nii.gz'))\n",
    "        #A2 = median_filter(A2, size=(3,3,3))\n",
    "        #A3 = load_volfile(os.path.join(atlas_dir,'atlas_L3-L5.nii.gz'))\n",
    "       # A3 = median_filter(A3, size=(3,3,3))\n",
    "        composed_atlas = Compose([LimitRange(), MyNormalize()])\n",
    "        # pretty put in one array\n",
    "        #composed_atlas = LimitRange()\n",
    "        A1 = composed_atlas(A1)\n",
    "\n",
    "        #A2 = composed_atlas(A2)\n",
    "        #A3 = composed_atlas(A3)\n",
    "        A1_mean = np.mean(A1)\n",
    "        A1_std = np.std(A1)\n",
    "        #A2_mean = np.mean(A2)\n",
    "        #A2_std = np.std(A2)\n",
    "        #A3_mean = np.mean(A3)\n",
    "        #A3_std = np.std(A3)\n",
    "        \n",
    "    \n",
    "    #-------for each of the batches, find appropriate atlas, limit range, normalize and stack the data-------\n",
    "    while True:\n",
    "        \n",
    "        idxes = np.random.randint(len(vol_names), size=batch_size)\n",
    "        \n",
    "        X_data = []\n",
    "        A_data = []\n",
    "        for idx in idxes:\n",
    "            current_vol = vol_names[idx]\n",
    "            \n",
    "            if current_vol[-9:-4] == 'L1-L3': \n",
    "                A = A1\n",
    "                A_mean = A1_mean\n",
    "                A_std = A1_std\n",
    "            elif current_vol[-9:-4] == 'L2-L4' :\n",
    "                A = A2\n",
    "                A_mean = A2_mean\n",
    "                A_std = A2_std\n",
    "            elif(current_vol[-9:-4] == 'L3-L5'):\n",
    "                A = A3\n",
    "                A_mean = A3_mean\n",
    "                A_std = A3_std\n",
    "            else: \n",
    "                print('wrong name:',current_vol[-9:-4] )\n",
    "            \n",
    "            #composed = Compose[LimitRange(),AdjustBrightness(A_mean,A_std),Pad(64)]\n",
    "            \n",
    "            # load and apply transformations to current volume\n",
    "            X = load_volfile(current_vol)\n",
    "            X = median_filter(X, size=(3,3,3))\n",
    "            composed = LimitRange()\n",
    "            X = composed(X)\n",
    "            X = mt.adjust_brightness(X,A_mean,A_std)\n",
    "           \n",
    "            #pad the data\n",
    "            pad = Pad(pad_size)\n",
    "            X = pad(X)\n",
    "            A = pad(A)\n",
    "            X = X[np.newaxis, ..., np.newaxis] \n",
    "            A = A[np.newaxis, ..., np.newaxis]\n",
    "            \n",
    "            ##stack the data\n",
    "            X_data.append(X)\n",
    "            A_data.append(A)\n",
    "        \n",
    "\n",
    "        if batch_size > 1:\n",
    "            return_vals = [np.concatenate(X_data, 0), np.concatenate(A_data, 0) ] \n",
    "            #print(return_vals.shape)\n",
    "            #print(return_vals)\n",
    "        else:\n",
    "            return_vals = [X_data[0], A_data[0]]\n",
    "\n",
    "        # also return segmentations\n",
    "        #if return_segs:\n",
    "        #    X_data = []\n",
    "        #    for idx in idxes:\n",
    "        #        v = vol_names[idx].replace('norm', 'aseg')\n",
    "        #        v = v.replace('vols', 'asegs')\n",
    "        #        X_seg = load_volfile(v)\n",
    "        #        X_seg = X_seg[np.newaxis, ..., np.newaxis]\n",
    "        #        X_data.append(X_seg)\n",
    "\n",
    "        #    if batch_size > 1:\n",
    "        #        return_vals.append(np.concatenate(X_data, 0))\n",
    "        #    else:\n",
    "        #        return_vals.append(X_data[0])\n",
    "\n",
    "        yield tuple(return_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
